{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('capstone.cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "iam_client = boto3.client('iam',\n",
    "                       region_name=config.get('AWS','REGION'),\n",
    "                       aws_access_key_id=config.get('AWS','AWS_ACCESS_KEY_ID'),\n",
    "                       aws_secret_access_key=config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "                      )\n",
    "\n",
    "redshift_client = boto3.client('redshift',\n",
    "                        region_name=config.get('AWS','REGION'),\n",
    "                        aws_access_key_id=config.get('AWS','AWS_ACCESS_KEY_ID'),\n",
    "                        aws_secret_access_key=config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "                       )\n",
    "\n",
    "ec2_client = boto3.resource('ec2',\n",
    "                   region_name=config.get('AWS','REGION'),\n",
    "                   aws_access_key_id=config.get('AWS','AWS_ACCESS_KEY_ID'),\n",
    "                   aws_secret_access_key=config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Creating a new IAM Role =====\n",
      "===== Attaching AmazonS3ReadOnlyAccess policy with the IAM Role =====\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('===== Creating a new IAM Role =====')\n",
    "    iam_client.create_role(\n",
    "        Path='/',\n",
    "        RoleName=config.get('IAM_ROLE','IAM_ROLE_NAME'),\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                'Statement': [{\n",
    "                    'Action': 'sts:AssumeRole',\n",
    "                    'Effect': 'Allow',\n",
    "                    'Principal': {\n",
    "                        'Service': 'redshift.amazonaws.com'\n",
    "                    }\n",
    "                }],\n",
    "                'Version': '2012-10-17'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('===== Attaching AmazonS3ReadOnlyAccess policy with the IAM Role =====')\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=config.get('IAM_ROLE','IAM_ROLE_NAME'),\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Creating Redshift Cluster =====\n"
     ]
    }
   ],
   "source": [
    "roleArn = iam_client.get_role(RoleName=config.get('IAM_ROLE','IAM_ROLE_NAME'))['Role']['Arn']\n",
    "\n",
    "try:\n",
    "    response = redshift_client.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=config.get('DWH','CLUSTER_TYPE'),\n",
    "        NodeType=config.get('DWH','NODE_TYPE'),\n",
    "        NumberOfNodes=int(config.get('DWH','NUM_NODES')),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=config.get('CLUSTER','DB_NAME'),\n",
    "        ClusterIdentifier=config.get('CLUSTER','CLUSTER_IDENTIFIER'),\n",
    "        MasterUsername=config.get('CLUSTER','DB_USER'),\n",
    "        MasterUserPassword=config.get('CLUSTER','DB_PASSWORD'),\n",
    "\n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "    print(\"==== Creating Redshift Cluster =====\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pretty_redshift_props(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keys_to_show = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keys_to_show]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def redshift_cluster_status(redshift_client, verbose=False):\n",
    "    if not redshift_client:\n",
    "        return\n",
    "    \n",
    "    cluster_props = redshift_client.describe_clusters(ClusterIdentifier=config.get('CLUSTER','CLUSTER_IDENTIFIER'))['Clusters'][0]\n",
    "    if verbose:\n",
    "        print(pretty_redshift_props(cluster_props))\n",
    "    return cluster_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::308990863356:role/capstoneRole'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roleArn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def open_access_to_cluster(ec2_client, redshift_client):\n",
    "    cluster_props = redshift_cluster_status(redshift_client)\n",
    "    if not cluster_props:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        vpc = ec2_client.Vpc(id=cluster_props['VpcId'])\n",
    "        defaultSg = list(vpc.security_groups.all())[0]\n",
    "        print(defaultSg)\n",
    "        port = int(config.get('CLUSTER','DB_PORT'))\n",
    "        defaultSg.authorize_ingress(\n",
    "            GroupName=defaultSg.group_name,\n",
    "            CidrIp='0.0.0.0/0',\n",
    "            IpProtocol='TCP',\n",
    "            FromPort=port,\n",
    "            ToPort=port\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def delete_aws_resources(iam_client, redshift_client):\n",
    "    if not redshift_client and not iam_client:\n",
    "        return\n",
    "    \n",
    "    redshift_client.delete_cluster(ClusterIdentifier=config.get('CLUSTER','CLUSTER_IDENTIFIER'), SkipFinalClusterSnapshot=True)\n",
    "    iam_client.detach_role_policy(RoleName=config.get('IAM_ROLE','IAM_ROLE_NAME'), PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "    iam_client.delete_role(RoleName=config.get('IAM_ROLE','IAM_ROLE_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0133c01b457d4df9f')\n"
     ]
    }
   ],
   "source": [
    "open_access_to_cluster(ec2_client, redshift_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'redshift_cluster_status' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8dda4c45199c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mredshift_cluster_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredshift_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'redshift_cluster_status' is not defined"
     ]
    }
   ],
   "source": [
    "redshift_cluster_status(redshift_client, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Connection timed out\n\tIs the server running on host \"dwhcluster.cqgurtquub8h.us-west-2.redshift.amazonaws.com\" (35.163.62.158) and accepting\n\tTCP/IP connections on port 5439?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9699bf8b7952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CLUSTER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DB_USER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CLUSTER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DB_PASSWORD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CLUSTER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DB_PORT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ))\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Connection timed out\n\tIs the server running on host \"dwhcluster.cqgurtquub8h.us-west-2.redshift.amazonaws.com\" (35.163.62.158) and accepting\n\tTCP/IP connections on port 5439?\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('capstone.cfg')\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(\n",
    "    config.get('CLUSTER','HOST'),\n",
    "    config.get('CLUSTER','DB_NAME'),\n",
    "    config.get('CLUSTER','DB_USER'),\n",
    "    config.get('CLUSTER','DB_PASSWORD'),\n",
    "    config.get('CLUSTER','DB_PORT')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cluster_props = redshift_cluster_status(redshift_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not cluster_props:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        vpc = ec2_client.Vpc(id=cluster_props['VpcId'])\n",
    "        defaultSg = list(vpc.security_groups.all())[0]\n",
    "        print(defaultSg)\n",
    "        port = int(config.get('CLUSTER','DB_PORT'))\n",
    "        defaultSg.authorize_ingress(\n",
    "            GroupName=defaultSg.group_name,\n",
    "            CidrIp='0.0.0.0/0',\n",
    "            IpProtocol='TCP',\n",
    "            FromPort=port,\n",
    "            ToPort=port\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "vpc = ec2_client.Vpc(id=cluster_props['VpcId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.Vpc(id='vpc-0720ee69b410d2f97')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "defaultSg = list(vpc.security_groups.all())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port = int(config.get('CLUSTER','DB_PORT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5439"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e88cace5-cadf-47aa-8754-54e349761fb4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e88cace5-cadf-47aa-8754-54e349761fb4',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '723',\n",
       "   'date': 'Fri, 15 Jul 2022 08:48:34 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultSg.authorize_ingress(\n",
    "    GroupName=defaultSg.group_name,\n",
    "    CidrIp='0.0.0.0/0',\n",
    "    IpProtocol='TCP',\n",
    "    FromPort=port,\n",
    "    ToPort=port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
